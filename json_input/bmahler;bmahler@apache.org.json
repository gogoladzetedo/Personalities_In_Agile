{"contentItems": [{"content": "Add GPUs to container resource consumption metrics.. Grant access to dev nvidiactl and in the Nvidia GPU isolator.. Calls to 'nvidia-smi' fail inside a container even if access to a GPU has been granted. Moreover, access to dev nvidiactl is actually required for a container to do anything useful with a GPU even if it has access to it. We should grant revoke access to dev nvidiactl and as GPUs are added and removed from a container in the Nvidia GPU isolator.. Currently the endpoint in libprocess has a rate limit of 2 requests per second: This should be configurable via a libprocess environment variable so that users can control this when initializing libprocess.. Libprocess endpoint rate limiting should be configurable.. Expose allocation algorithm latency via a metric.. The allocation algorithm has grown to become fairly expensive, gaining visibility into its latency enables monitoring and alerting. Similar allocator timing-related information is already exposed in the log, but should also be exposed via an endpoint.. Add allocator metrics for total vs resources.. Add an abstraction to manage the life cycle of file descriptors.. In order to avoid missing calls on file descriptors, or double-closing file descriptors, it would be nice to add a reference counted in a similar way to what we've done for Socket. This will be closed automatically when the last reference goes away, and double closes can be prevented via internal state.. On Linux, retrying close on EINTR is dangerous because the fd is already released and we may accidentally close a newly opened fd (from another thread), see: It appears that other OSes, like HPUX, require a retry of close on EINTR. The Austin Group recently proposed changes to POSIX to require that the EINTR case need a retry, but EINPROGRESS be used for when a retry should not occur: However, Linux does not follow this and so we need to remove our EINTR retries. Some more links for posterity:. Perf event isolator stops performing sampling if a single timeout occurs.. Currently the perf event isolator times out a sample after a fixed extra time of 2 seconds on top of the sample time elapses: This should be based on the reap interval maximum. Also, the code stops sampling altogether when a single timeout occurs. We've observed time outs during normal operation, so it would be better for the isolator to continue performing perf sampling in the case of timeouts. It may also make sense to continue sampling in the case of errors, since these may be transient.. Add support for to aid isolators controlling access to devices. In the future, we could think about how to numerate and control access to devices as resource or task container policy. The gold linker seems to provide a decent speedup (about on a parallel build. From a quick test: gold: real user sys default ld: real user sys sudo ld Ideally we could this out on the website, with instructions for each OS.. Adding this handler lets master send Event messages to the driver. See MESOS-2909 for additional context.. should expose metrics on oversubscribed resources (allocated and available).. should expose metrics on oversubscribed resources (allocated and available).. Add - operator for Option, Try, Result, Future.. Rather than using ifdefs, have you considered implementing it for OS X POSIX systems through other means? fork an intermediate process that polls for the existence of the parent, or fork an intermediate process that reads a pipe from the parent (EOF parent death).. Rate limit slaves removals during master recovery.. The master's endpoint consistently takes a long time to compute the JSON result, for large clusters: This can cause the master to get backlogged if there are many requests in flight. Looking at data, it seems most of the time is spent doing memory allocation de-allocation. This ticket will try to capture any low hanging fruit to speed this up. Possibly we can leverage moves if they are not already being used by the compiler.. Observed this on internal CI. killTask() should perform reconciliation for unknown tasks.. Currently, uses its own reconciliation logic, which has diverged from the logic. Specifically, when the task is unknown and a non-strict registry is in use, will not send TASK LOST whereas will. We should make these consistent.. Expose number and state of threads in a container. Based on MESOS-1474, we'd like to provide an HTTP API on the master for the maintenance primitives in mesos. Something like this for manipulating the schedule: GET POST many hosts POST single host DELETE single host Something like this for checking the status progress: GET These need to be authenticated and authorized.. The initial use case for InverseOffer in the framework API will be the maintenance primitives in mesos: MESOS-1474. One way to add these to the Python Scheduler API is to add a new callback: Egg libmesos compatibility will need to be figured out here. We may want to leave the Python binding untouched in favor of Event Call, in order to not break API compatibility for schedulers.. The initial use case for InverseOffer in the framework API will be the maintenance primitives in mesos: MESOS-1474. One way to add these to the Java Scheduler API is to add a new callback: JAR libmesos compatibility will need to be figured out here. We may want to leave the Java binding untouched in favor of Event Call, in order to not break API compatibility for schedulers.. The initial use case for InverseOffer in the framework API will be the maintenance primitives in mesos: MESOS-1474. One way to add these to the C++ Scheduler API is to add a new callback: libmesos compatibility will need to be figured out here. We may want to leave the C++ binding untouched in favor of Event Call, in order to not break API compatibility for schedulers.. InverseOffer was defined as part of the maintenance work in MESOS-1474, design doc here: This ticket is to capture the addition of the InverseOffer protobuf to the necessary API changes for Event Call and the language bindings will be tracked separately.. When a slave re-registers with the master, it currently sends the latest task state for all tasks that are not both terminal and acknowledged. However, reconciliation assumes that we always have the latest unacknowledged state of the task represented in the master. As a result, updates are possible, (1) Slave has task T in TASK FINISHED, with unacknowledged updates: . (2) Master fails over. (3) New master re-registers the slave with T in TASK FINISHED. (4) Reconciliation request arrives, master sends TASK FINISHED. (5) Slave sends TASK RUNNING to master, master sends TASK RUNNING. I think the fix here is to preserve the task state invariants in the master, namely, that the master has the latest unacknowledged state of the task. This means when the slave re-registers, it should instead send the latest acknowledged state of each task.. The slave does not send pending tasks during. In what looks like an oversight, the pending tasks and utors in the slave are not sent in the message. For tasks, this can lead to spurious TASK LOST notifications being generated by the master when it falsely thinks the tasks are not present on the slave.. As we update the Master to keep tasks in memory until they are both terminal and acknowledged (MESOS-1410), the lifetime of tasks in Mesos will look as follows: In the current form of the slave sends to the master all tasks that are not both terminal and acknowledged. At any point in the above lifecycle, the slave's message can reach the master. Note the following properties: The master may have a non-terminal task, not present in the slave's message. The master may have a non-terminal task, present in the slave's message but in a different state. The slave's message may contain a terminal unacknowledged task unknown to the master. In the current master slave code, the master assumes that case (1) is because a launch task message was dropped, and it sends TASK LOST. We've seen above that (1) can happen even when the task reaches the slave correctly, so this can lead to inconsistency! After chatting with , we're considering updating the reconciliation to occur as follows: Slave sends all tasks that are not both terminal and acknowledged, during This is the same as before. If the master sees tasks that are missing in the slave, the master sends the tasks that need to be reconciled to the slave for the tasks. This can be piggy-backed on the message. The slave will send TASK LOST if the task is not known to it. Preferably in a retried manner, unless we update socket closure on the slave to force a. We currently do not log the user id when receiving a SIGTERM, this makes debugging a bit difficult. It's easy to get this information through sigaction.. We've observed issues where the masters are slow to respond. Two perf traces collected while the masters were slow to respond: These have been found to be attributed to the posix fadvise calls made by glog. We can disable these via the environment: We should set prior to making our call to to avoid others running into this issue.. ", "contenttype": "application/json", "created": 737603, "id": 50, "language": "en", "user_name": "bmahler", "email": "bmahler@apache.org"}]}
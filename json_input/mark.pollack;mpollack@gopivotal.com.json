{"contentItems": [{"content": "Update Spring-AMQP to RabbitMQ Client to. Enable in line SSL properties as an alternative to external properties files. Encrypt secret information in XD configuration files. Add maxWait property to set in kafka message bus. resolves resources once. Create separate doc sections for reactor-ip's tcp and udp functionality. Provide a source option to enable the SOF EOF markers when splitting a file into lines. As a developer, I'd like to remove ID and TimeStamp attributes from the class, so I can improve performance by not having them go through instead, we could leverage message headers to collect such information.. Provide more informative error message when fails in Tuple. Improve performance of TupleBuilder. Upgrade to SIK release. Properly render defaults for that use n t etc.. Might be worthwhile to put in. Creating Streams sporadically using Kafka as a message bus throws TopicNotFound exception. Remove Reactor Stream processor from ref docs to. Update HdbcHdfsTest if necessary to make sure new ItemWriter implementation is working.. Spark streaming integration with kafka message does not respect config option. Add support for Sentinel in Redis Sink. Support rapid creation and deletion of streams. Configure Redis Cluster with Sentinal v Verify fail over, experiment with settings. Useful reference All analytics test cases should be run as well as test that deploy streams that make use of redis analytics. There might be some minor code changes required as mentioned in the flickr article.. Test Redis Sentinal setup and document recommended configuration. Create reactor module in project. As an developer, I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava. A plugin should allow a reactor processor module to specify the bare minimum to work, the processor class. Explore how additional configuration can be achieved with well known module option commands.. Update reactor-ip and syslog modules to Reactor RC1. As an engineer, I'd like to upgrade to Reactor SNAPSHOT and then RC1 release so that we can synchronize with stable dependencies.. Upgrade to Reactor RC1. Fix version here said need to make sure this is only applied to the master branch, not. Reference documentation on RxJava Stream processor. Create plugin module for reactor based processors. As an developer, I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava. A plugin should allow a reactor processor module to specify the bare minimum to work, the processor class. Explore how additional configuration can be achieved with well known module option commands.. Create MessageHandler for RxJava based processor modules. As a user, I'd like to have a flexible RxJava module so that it can as a processor.. Define developer facing interfaces for RxJava processors. As a user, I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.. Refactor use of in integration tests. Add Request Reply support to Kafka message bus. The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other. Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.. As a developer, I'd like to include the following improvements as part of the EC2 CI so that we can reliably run the CI builds and also assert over feature Change from using artifactory gradle task to a command task (that calls . gradlew) Turn on. Adding fails with classMethod FAILED classMethod FAILED. Investigate test failure in CI builds. Same as for XD-228. Rerun test XD-2278 on a EC2 32 core machine and see when we max out.. Vary Producer and Consumer in combination using 2 Queues (B-6). Getting Caused by: Could not open JDBC Connection for transaction; nested exception is S Invalid or (currently) unsupported isolation level, '8', passed to Conn The currently supported values are and Source) at when launching a simple batch job with GemXD configured as the database job create myjob \"filejdbc job deploy myjob job launch myjob spring: datasource: url: username: admin password: admin. Measure baseline performance of RabbitMQ using PerfTest (In-house). In there are tests that exercise various commands. Create a new test that starts xd-singlenode with authentication enabled, ute the admin config command with credentials, and then make sure a request, such as module listing, is returned successfully from the admin server.. Providing and options when starting the shell.. As a user, I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic auth Technical Add and to the admin config command.. XD Shell needs to be be able to authenticate using basic auth to admin server. Create a JUnit test, possibly extending the one for XD-2143, that provides the expected user password when making a request to the root XD endpoint The configuration of the RestTemplate used in should contain the correct credentials.. A JUnit test in or in that will start up singlenode server with basic authentication enabled via the property There should be a test method that ensures you get a challenge response when requesting a GET on the root XD endpoint A sanity check is to request a boot endpoint such as. As a user, I'd like to have the option of Basic Auth so that I'm challenged to provide user name and password when making a request. Technical This functionality is provided in Spring Boot it should be a matter of adding the spring boot security starter dependency to the project. It will be controlled using the spring boot property true false. Our default in for this property should be false.. Set up a test that runs singlenode server and uses a configuration with the properties 8443 secret another-secret There maybe a key-store used for some of the scp tests that can be reused. The test also needs to configure to make requests using. DSL shell and Admin UI (part of other stories). As a user, I'd like to have the option to enable HTTPS so that I can access XD's Admin server over secured communication. Technical This functionality is available in Spring Boot M1 and has been backported into the branch to be released under Spring We can test against SNAPSHOT. Working through the way to update the build file to pick up a new version of boot is a bit tricky :(. Redis fails when end of interval is on the hour. Noticed a few issues while reviewing the documentation Somehow the section is giving an error. asciidoctor: WARNING: line 167: invalid style for paragraph: appendix asciidoctor: WARNING: line 169: include file not found: :distZip but I don't notice anything different between that appendix and the others in. Removed various TODO comments in code and put here for proper triage. DefaultTuple Ctor visibility. Consider making ctor final and package protect the ctor so as to always use TupleBuilder top level methods to add. String somethign that would indicate which stream or job this tuple is being processed * do we want to not map id and timestamp (believe the answer is don't map, preserve original). Spring provides a UUID generator (used by default in SI) that should be used instead of the library in the xd-tuple library. In EC2 deployment, Allow users to set download jars into the lib xd directory. Packaging of Guava 17 results in failure to deploy mapreduce job to Hadoop based distros. Change logging level to INFO. Dependendcies for Hadoop distros are broken. Update to Spring Shell RC4. Use Boot plugin and IO Platform for versions where possible. Create documentation section on best practices. Update to Spring Platform. Use 2 tabs for hidden options in shell. Provide ability to disable tab completion for specific module options. Module option validation not happening anymore. Create equivalent tests in which are only present in the script based tests.. Increase performance of query to determine Job restartability. Tap Fixture refactoring. Do not allow the use of named channels in composed modules. Update to use katyperry. Investigate need for UI Pagination. Assess XD Fails to connect to remote Redis Instance. Support the ability to create module definitions in Groovy. Create System Tests for Partitioning. Upgrade ZK installation on EC2 to. Update data partitioning functionality to use murmur hash function. Assess if & gemfireServer sinks should close the client cache. Fix brittle tests in CI environment. Update CI server to run tests that depend on rabbit redis and hadoop. you did not use the option in reactor-ip. Investigate fall through of values when running in YARN. Remove dependency on Sprint Boot in xd-dirt tests. Support for UUID suffix for hdfs file names in acceptance tests. Update dependencies in Spring XD Sample Repository. needs to use http as its test source. Secure REST endpoints. We would like to provide optional security configurations to secure REST endpoints of xd-admin. Spring security integration in Boot can be leveraged to provide authentication and authorization.. Test integration with jboss queue message. Update to snapshot builds of Spring Shell. Tests are failing due to change in JMX endpoint data. Add Twitter Stream tests acceptance tests. Add Twitter search module tests acceptance tests. Update HDFS sink to use unique id (GUID) as part of file name. Update HDFS sink to accept a partition strategy. Based off Provide test coverage for all batch jobs and. Refactor Exception Handling and update JavaDocs for acceptance test. following the HTCondor model for resource assignment, the use of a 'rank' expression that evaluates to an integer is used to order the containers that match the current 'criteria' expression. This allows you to setup ranks such as 'prefer the machine with the most free memory' or 'prefer a machine from groupa' (higher rank values match first). From HTCondor Presentation Rank A machine with a higher number will be preferred over a machine with a lower number. Rank Examples Rank Mips Rank Memory + 100 Prefer machines with a high ratio of memory to cpu performance: Prefer machines that will checkpoint in Bologna: ** Rank. Will change the launch scripts to default to local transport unless it is specifically passed with the option.. Move resusable analytics repository classes to a new project.. i can't seem to comment anymore on the spring shell issue so i'll put the details here I am not happy with the fix I made, see Without understanding yet why we exclude the situation asserted for in the test above, this solution has two shortcomings 1) introducing a new method level annotation. Now that i think of it, adding a property on would probably better, but even better would not be introducing anything new like this at all. Having the new annotation on the method level means it applies to all command arguments, though i suppose this case will only involve commands that have one 'pass through' parameter. 2) it would be nicer to avoid calling the tokenizer at all if we know that the text should remain 'untouched'. I was not clear of how to put the 'key' of the Map options null; in all cases, in this specific case it is empty string \"\" but perhaps could be other values.. Support deploying to multiple containers in EC2 acceptance tests. Need to be able setup ec2 env to test job samples in repo. Reduce amount of logging at server startup. Prevent submiting jobs that are not currently deployed using Admin UI. Merge Container and as well as their \"repositories\". Update document for the distributed runtime based on RC1 changes. ZooKeeper runtime cleanup and refactoring. Delete post module and CF profile. Use Hadoop mini-cluster test support in XD tests. Update Spring-AMQP to. Implement & NAME. The description in the google doc describes the usage of and. 0. Remove home page with sign in and upper right hand corner with user login info. 1. Change the word template to modules in the tab 2. Different text for each of the tabs, modules, definition, deployments, scheduled 3. Definitions tab to have text along the lines \"allows you to deploy and undeploy batch job definitions\" add links to help on how to do that in the CLI. 4. Deployments tab a creating new definitions, - parameters needs to be space on parameters, Job Parameters for Job XYZ after clicking launch. b. comment out scheduler button c. add quick filter 5. Scheduler tab a. comment out tab. Fix existing Karma unit tests in XD admin UI. The sample application should primarily show the 'round trip' that is possible in that \"offline\" analysis in R can generate a pmml flle that can be imported and evaluated in an \"online\" stream definition. The specific use case can be as simple as the IRIS data set or other existing examples, such as the fraud demo. The sample application resides in. Create documentation for the core analytical model abstractions and use of jpmml processor. Inconsistent test failure with mqtt script test in CI environment. Create project. Create a throughput sink. The application should live in in repository. The stream created in should be documented how to run a benchmark and made easy to ute. Can use to generate traffic via sendfile in order to saturate the stream.. Add new reactor tcp module. Upgrade to Spring Batch M3. Add JDBC & JMS Sinks and sources to acceptance tests. Improve job launch functionality with distributed nodes. When sending a launch request, the message is not targeted to the container node that hosts the deployed job. With RabbitMQ, the message is not ack'd so it will get picked up eventually by the container that hosts the deployed job. This should change to a targeted message. Original description from Thomas below Tried deploying some batch jobs and they all seem to fail when running admin and one container using redis as transport create mongojob \"hdfsmongodb fails with this: WARN - Error handling failed (Error creating bean with name Initialization of bean failed; nested exception is has not been refreshed yet) ERROR - error occurred in message handler at Caused by: Error creating bean with name Cannot create inner bean '(inner bean)' of type while setting bean property 'listeners' with key ; nested exception is Error creating bean with name '(inner bean) 4': FactoryBean threw exception on object creation; nested exception is interface is not visible from class loader 18 more Caused by: Error creating bean with name '(inner bean) 4': FactoryBean threw exception on object creation; nested exception is interface is not visible from class loader at 41 more Caused by: interface is not visible from class loader at 43 more I'll post more errors as I collect them. Add acceptance tests for stream with sources of TCP, HTTP, and Time and sinks of File and Log. Create spike of web app that maps UI design docs to MVC components in Angluar. Clarify API or syntax for managing deployment parameters. Switch to use Jedis driver for Redis. Deployment manifest to support directing deployment to run on a group of servers. Deployment manifest to support partitioning a stream. Test working on Apache distribution We can modify config files, everything should be possible to override by providing command-line args or env variables. There seems to be some intersection with the work for this issue and the of how module properties are handled. There will be changes to management support such that each module (source, sink, etc) will be able to also be overridden in (or wherever points to. The HDFS sink module for example, will have default values based on it's and will be of the form .. That means in the configuration for sink, there would be a config section such as With default values defined by a class. The module file would not contain any references to a properties file. A file specified by could override the values in a config section such as sink: hdfs: : : etc.. Support for deploying and running XD on YARN. Create POJO based FileSink module metadata. Move ftp support from .x package to batch package. Need a way to tell the user that this option will be determined at runtime,late bindings. In the module info command, references to $ could read \"\" for example). create simple \"http transform filter transform file\" Created new stream 'simple' create tapSimple file\" Created new stream 'tapSimple' There isn't a stream named I don't remember if we want to allow for this (set up taps before there is a stream) or if it should be an error. Otherwise, works as expected create tapSimple2 file\" Command failed 11): Reference to 'transform' is not unique in the target stream 'http transform filter transform file', please label the relevant module and use the label, or use a suffix index to indicate which occurrence of the module,. This is about computing the value to support expressions such as $ as a default. Initial discussion suggested to leverage the work done in XD-1175 by having a custom (or etc) be resolved at deployment time. Update SI to latest M3 and Spring AMQP to. Develop basic acceptance test application to exercise based XD-EC2 deployment from CI. Create a first pass at an acceptance test app for a stream definition of http log. This will involve creating two new projects in xd 1. 2. 1 will contain generally useful utility methods for acceptance test, such as sending data over http, obtaining and asserting JMX values of specific modules. 2 will contain tests that use 1 to test the various out of the box modules provides in XD.. Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit. Add stage to Acceptance Test EC2 build plan that runs a basic acceptance test application against the single-node deployment. Run test application developed in XD-1245. Add to Acceptance Test EC2 CI build plan a stage that stops any existing CI EC2 deployments. Create EC2 AMI for single-node install of Pivotal HD. Create EC2 AMI for single-node install of Apache Hadoop. Create EC2 AMI for single-node install of Apache Hadoop. Provide a easy, prescriptive means to perform unit and basic stream integration tests.. xd-admin server to as an option.. Support use of fragments. Enabling of JMX support is broken. If I fiddle with the method I can reproduce the same issue: HttpSource source FileSink sink FileSink tapsink1 \"%s flibble: transform flibble2: transform %s\", source, sink); transform %s\", tapsink1); Expected: trying at most 10 times but: failed after 10*100 1000ms:. Splunk module is broken. Create integration test script for JMS & MQTT. Allow local data transport option for the container. Allow alternate transports to be used within a stream. Basic support for Plugin contributed Module Options Metadata. Add support for deploying a batch job with partitioning across multiple XD nodes.. Functionality adopted from spring batch admin Should include springmvc test framework style tests DELETE utions Stop a specific job. Functionality adopted from spring batch admin Should include springmvc test framework style tests GET - Get information on a given step ution. Adopted functionality from spring batch admin Should include springmvc test framework style tests GET - Get information on all steps of a given job ution. Adopted functionality from Spring Batch admin Should include springmvc test framework style tests GET utions - Get information on all utions of a given job name.. Create REST API for getting information on all job utions for a given name. Develop out a Proof of concept for review that allows users to easily create a new Java based module to Spring XD. An ideal flow would be 1. In the shell, have a command to create a new custom module - for example a stream processor. This would pick the appropriate starter pom to create an XD application. 2. Open up the project in an IDE. There should be a shell of code that has a Processor module and also something in the test directory the shell of some code for testing the module. 3. On the command line, issue a command equivalent to mvn that would build, test and create an packaged file (single) that can be dropped into a module registry directory The same general flow would apply for batch jobs. ATM XML centric stream defs batch job defs would be sufficient. Having the option for JavaConfig style batch job definitions would be nice as there isn't a DSL for batch jobs (and likely won't be except for a trivial case). One shouldn't have to restart the xd-container in order to use this new processor.. Change default container port from 9000 to something else. Add bridge module. Add support for Hortonworks Data Platform. This will allow for some easy demonstration of how 'HATEOS' works via links in our REST API. There are probably some quite useful commands here that could be used from the Spring Data REST shell longer term, but a good place to take a look at now. Goal is to show how metrics such as counters are accessible w o having to switch tabs to use wget. The pretty printing of the returned JSON is an important feature to help understand the response, this functionality can be taken from reused from the Spring Data REST shell. This relates to XD-871 which provides a good scenario. stream create s1 \"http log stream create s2 \"http log The second command results in an error message that the port is in use but the stream definition is still saved. Since create + deploy is a logical unit of work, it should follow transactional semantics. In other words if the deploy fails, the repository should be rolled back (or a compensating destroy should be performed). Note this should not be handled the same way if create and deploy happen separately. In that case, the stream definition should remain.. Use a modal dialog to specify runtime parameters. There should be a little text are that gives hints as to the spring batch parameter key value conventions, for type. Might be a good idea to have a checkbox that lets you select to 'auto increment' job instance number. 4 columns key, value, type, identifying and an 'add parameter' button that adds a new row. This would appear as a modal dialog box, polling of the state of the deployments would be suspended while the job parameter modal dialog box is shown.. DataSource for batch infrastructure should be configurable, not hardcoded to hsqldb. Don't perform error-level logging for normal application behavior in batch admin functionality. UI: User should be able to filter the list of utions on the ution tab. On clicking a specific job name in the deployed jobs list, we need to redirect the user to show the list of all the job utions on that job. User should be able to navigate back to the deployed jobs list.. The HDFS Sink should support writing POJOs to HDFS using Avro Kite SDK with support for partitioning. Writing POJOs using Kite SDK. The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structure The ItemProcessor will be a no-op groovy script. The ItemWriter will write the data to a MongoDB collection the sample job should be documented*. Create a new tasklet implementation that will use the ANT globbing like syntax found in to specify the input files, and use FsShell to invoke a command with a specified HDFS output directory. The batch job would call the tasklet.. Create OOTB stream that polls for files in a directory and launches a batch job.. Same processing as XD-984, but the job instacne is launched via an event from the input file source. Supporting a single file per job launch is OK. job create blah \"filehdfs\" stream create csvStream \"file the job should be documented*. Create OOTB batch job for import and processing multiple files to JDBC. Create a sample batch job for inclusion in the distribution that will perform the following tasks. ItemReader Support for CSV (assume first line has header values) Provide groovy based no-op ItemProcessor. (configurable) ItemWriter Provide The sample job should be documented**. Writing to HDFS -. OOTB batch jobs for common cases. Add functionality to download XD distribution zip to each EC2 instance as specified by user. Copy the distribution from the shared EBS S3 the ebs volume assigned to the each node admin instance . Unzip the distribution from on the ebs volume for the instance to the home ubuntu directory Create a JUNit style integration test that Invoke the application functionality (should be a 1 liner) that will start up the instance and download the .zip distribution from the URI provided in Verify the file is now in EBS S3 and also on the instance Create new instance passing in the same URI of the .zip distribution. Verify as before. Create CI for XD-EC2 project. Add functionality to provision EC2 instance and mount EBS. Create a Spring Application Context. Associate EBS shared volume for each machine instance Use gradle application plugin to generate a bin directory with a script to start the application. See Create a POJO to easily reference these properties, vs. using a raw java Properties object. How to verify it works Create JUnit based tests. JClouds itself has extensive testing, can look at those for structure. Verify ports are open Instance Information Report successful and failed Instances. Key-Value pairs in configuration file properties may include: the access key assigned to you by admin the private key file assigned to you by admin. Used for ssh-ing into number of to deploy for this cluster. Value is an integer 0 url to download the XD to install. for example: * ami The ami image to use for your cluster. for example: ami-dfadsfdadf. Spike for job that exports HDFS CSV data to JDBC. Spike for job that imports data from CSV file to HDFS. SPI for deployment on to YARN + Local 'dirt' cluster.. Find runtime modules by type and or name. Document REST API. Add documentation for jsonPath functionality with SpEL based processors. Create FsShell based module to copy a File to HDFS. For file based item reader jobs, step job completion message should have name of file sent on named channel. Make in-memory meta data stores persistent. Support for listing of modules in the REST API. Apart from sanity checks, there is not much that ties to actual Using the Resource abstraction would work just the same, and would allow loading modules from the classpath in constrained environments or other file (HDFS HTTP). JAR version mismatches. Tap and using numbers instead of module names.. Fix Compiler Warnings. Support for composed streams. Updgrade to use M1 when available. Once is available, update the build to use it. Likely to be Sept 7 or 9. Add Named Channel API. Add Integration Tests to run JobCommands Tests against all transports. Should it be fatal vs. warning?. Avoid use of module name twice in location when using a custom modules. Add validation on tap definitions that checks for module names that are part of the stream definition. This is issue depends on XD-761. We should depend on $ $ we are using spring batch We need to depend on version. Spring Batch Admin provides a complete, but outdated implementation style, which covers the full administrative lifecycle of batch jobs, their creation, stop start, and retrieving information about previous job utions and the status of currently uting job utions. SpringXD has a different way of deploying, starting, and stopping jobs - by sending messages to containers that run the batch job. However, the reporting state of a job is still stored in a common job repository. The purpose of this story is to take the first step to merging in the existing code base that focuses only on the retrieval of information from Spring Batch Admins Job controller. The current REST API style of these commands should stay as close to the original spring batch admin style as possible. There are several reasons for this 1. It works, and time to springone is short, and we mgmt has expectations around deliverables that we must strive to meet. 2. It gives Andrew a working contract to start developing a UI 3. We can take on this technical debt, but refactor after RC1 and before GA while and deliver end-user functionality. Attached is the list of endpoints in spring batch admin. Support for based module definitions. Support use of separate control and message transports. Update Gemfire, Transport, and Job Launch docs. Support of Message payloads across JVMs across all transports.. Add support for dynamic routing. Support polling configuration for named channel queues in CLI. Support explict named channel creation with configurable settings via the REST API and Shell. Update error message for usage of hadoop rm with option. Document JSON quoting behavior in shell. Document queue channel capacity configurable when using local transport. results in both in-memory and redis based definitions of - can't satisfy autowiring because there are two candidates. Had to change to get the application context to load.. Change http command to post data by putting 'http' as the main command option. reproduce 1) Create a bad stream definition name 'bad' Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists.. Add additional options to File source. Adapt SpringOne 2012 UI code from keynote demo of election results to use XD. Check for high CPU usage with module. Address already in use for tomcat hsqldb should fail completly. Support pagination in list() command for streams. Avro sink for HDFS. Modify startup script of to allow specifying hadoop distro to use. There's a lifecycle problem when a tap creation fails because the DSL syntax is wrong). Subsequence attempts to create the tap will fail with an error: Disabling JMX solves the issue. reproduce Create a bad stream definition name 'bad' Try to recreate with the same name, but correct stream definitions. The system will report that the stream already exists.. Deploy Spring XD on Hadoop YARN. Homogenize Container Initialization Failures. Update Creating a Processor Module section to use Shell commands instead of curl. Document Monitoring & Management Features. Add section to documentation that shows command line options available for each server. Refactor exception classes. Create design document for implementation strategy for ingesting data from twitter into HDFS that can be analyzed by HAWQ. Create Repository. Add support for creating a spring batch job that has an embedded trigger expression. Simple cron based triggers. Add support for creating named cron triggers. Need to understand how individual modules may or may not share Dispatchers that are part of the parent context. If modules have their own dispatchers, those also need to be configurable.. Investigate Reactor-based Dispatchers in the common that can be used by Modules. Esper based Complex Event Processing module. Investigate JMX object naming of deployed modules and channel adapters.. Support for creation (POST) of tap. Add command for deleting a tap. User to send a message directly to module and receive a message from a module. Improve user experience when XD fails to start. File sink should support rollover. Provide a strategy interface to obtain the key used when writing SequenceFiles. Writing POJOs using CDK Data (Avro) We should support both partitioned and This story addresses only Document limitations in terms of which Java types are supported and not supported by the Avro serialization. note, the LZO codes are GPL-licensed, so can't be included in the distribution. It is splittable, which makes it a good candidate for writing without any additional data file container structure such as sequence or avro files.. Support writing to HDFS text file using the LZO codec. Support writing to HDFS text file using the BZip2Codec. Investigate throughput performance writing to HDFS. This could be an optimization, to be verified, that delegating the writing operations to Reactor with a backing ringbuffer will increase the throughput performance. Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.. h2. Narrative As XD, I need a persistent way to register job definitions (beyond the map registry implementation provided by Spring Batch). h2. Acceptance Criteria XD should be able to register, unregister, and find job definitions via the registry. The registry should be backed by Redis so that it is persistent.. Create JobDefinition repository. Retrieve description of all registered modules. Add command for deleting a stream. Add command for listing streams. Type conversion and co-location of modules. When a module is deployed, it should run in its own isolated classpath. The current code has all dependencies in a single classpath, taken from the lib directory at startup. This has a number of drawbacks, one of the most important is the batch jobs can not be contributed to the system at runtime. The work for this epic is decoupled from any module deployment story. The assumption is that there will be a directory layout as shown below. Current layout And inside source Using an example of the source directory from the current the new layout would be We should support both the new and old layout styles There what is under 'file' directory is the 'package' No .zip, war, is required.. Deploying Custom Code. Modules (sinks, processors, sources) should be able to be easily tested inside the IDE using JUnit. Support various output format, Avro, SequenceFile, more advanced rollover options.. Add Twitter gardenhose source module. Add RabbitMQ source module. Add support to load a file in the source. Documentation for developing streams in the IDE needs to mention including scripts dir to project classpath. can make use of the system property inside an import statement. This determines which version of the XD infrastructure to load, for example what implementation, Local or Redis based, or specific message listener containers. File name conventions should be used, so if the option passed in from the command line is localChannel then the XML filename looked for has the 'Protocol' suffix applied, and is loaded via the classpath. Redis and Local will not be the only options, other will be provided in the future, Rabbit, and the user may be able to provide their own of these infrastructure classes (an advanced task).. Document how to create a custom input output module for existing SI channel adapters. Add more structure, more easily find the reference guide. The style that is here is nice.. Validate processing modules declare the required channels. Create design document for implementation strategy to support message conversion in ChannelRegistry. Add HTTP Delete Stream Operation. Publish golo themed docs documentation to as part of nightly build. Parameter parsing does not work if an argument contains '. Expose shutdown operation over http. Verify use of JMX managed bean to shutdown cleanly the xd-admin and xd-container servers. Create externalized property file to support connectivity to redis. Documenation for redis servers. Based off SI tcp inbound adapter. This will allow for event forwarding that can select among the existing SI options.. Clean shutdown of redis in xd-container. Find and eliminate package-level cycles across XD projects. Documentation for starting Spring XD servers. A ctrl-c of xd-admin results in exception messages about disconnecting from redis. ERROR - Redis command interrupted; nested exception is Command interrupted. Clean shutdown of redis in xd-admin. $ processing module 'Module ' from group 'tailtest' with index: 1 processing module 'Module ' from group 'tailtest' with index: 0 Logging of 'processing module' should have log level,. Container server does not log a message that it has started or stopped successfully. Create XDContainer class to start stream server. Provide optional command line arg to embed the container launcher, aka - xd-admin server.. Add gradle tasks that build and bundle the redis server. Documentation that introduces taps. Documentation for \"syslog file\" processing. Documentation for \"http hdfs\" processing. Documentation for \"http file\" processing. Add gemfire-server application to the distribution zip of the project. Export of data from HDFS to MongoDB. Submit a brew-based install for Spring XD. The gradle application task should get us most of the way to create a distributable artifact akin to what you see when downloading tomcat jetty etc. Now there is a launch task task(launch, dependsOn: 'classes', type: JavaExec) The same main should be referenced in the application plugin, a task to create a .zip distributable is needed. Ideally would be nice to 1. download .zip 2. unzip 3. cd spring-xd bin 4. xdserver start and gracefully shutdown later with 5. xdserver stop I don't know if we can should bundle redis, I think we should bundle it. The scripts can be for unix linux and for windows. Discuss a brew based install as well.. SI for an XD Metrics backed Field Value Counter. Remove the expiry of keys in Redis based repositories. multi project build. - look to Spring Framework for source of starting point.. This should be usable within a single JVM process. Lives within shared application context of the process.. Define the interface.. A field-value counter is useful for bar chart graphs, Strings on x-axis and count on y-axis. Maps well to zset in redis. for in-memory and redis.. A simple counters can a number. for in-memory and redis.. Create a simple counter service. A rich gague stores a number and also rmd, min, max. for in-memory and redis.. A gauge just stores a number. for in-memory and redis.. Initial simple handcoded implementation for straight through pipe and filter model, a b c. A module groups together a collection of spring configuration files.. Create Module base abstractions. DIRT Runtime that deploys an application context across multiple nodes using redis.. create enough of a design to develop additional stories.. Design for deploying XD on EC2. Initial work that uses the module architecture from DIRT. Reactor based http ingestion. When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.. Basic implementation of a reactor based tcp server. Have a config file that can be added to a module and registered with a module registry.. The tuple data structure should be backward compatible in functionality for use in spring batch. Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.. Simple runtime that can start stop applications context.. Simple file writer that has existed in the spring hadoop samples.. HDFS Core writing helper classes. HDFS ItemWriter. Base integration of core HDFS writer functionality with Spring Batch.. ", "contenttype": "application/json", "created": 737603, "id": 1, "language": "en", "user_name": "mark.pollack", "email": "mpollack@gopivotal.com"}]}
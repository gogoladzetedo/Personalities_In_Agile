{"contentItems": [{"content": "Create Composed Job Module. h2. Narrative As a XD user, I'd like to restart the composed job workflow from Shell UI.. h2. Narrative Verify that the job launch works as we expect for the composed job.. h2. Narrative As the xd user, I would like a way obtain the result of each child job as it is represented as a step in the parent job's graph. h2. Back story Each child job will have a completion status of its own that will be displayed in the Spring XD UI as well as the shell's job ution list.. Develop tasklet to ute a Job. As an XD developer, I'd like to create a to ute a job. This is so that we have a way to ute each Job in the graph of a composed job. This is done by invoking the correct REST endpoint for the step in the graph.. h2. Narrative As an XD developer, I'd like to explore options to represent composed job, so I can create a workflow to orchestrate multiple jobs. h2. Back story For the composed job story, we need to create a \"real\" job module to be expressed in XML, so that we can take advantage of the job ution tasklet in XD-3556, so that each job can be uted as a step in the composed job.. POC prototype available for design review. * Composed job Module should not be visible from the module list command.. Support to compose batch jobs. Create a standard way to configure Spring Cloud Data and Stream projects. Add Spring Cloud Config to SPI Module Parent. Add support to expose counter metrics for dashboarding. Currently the fails on line 156 stating data is different in table that what is expected. Currently this is failing on the single deployment using redis as a transport. Also seeing the following exception in the attached log: The file is should be present and data present for the test. At least according to the checker on EC2 and local deployments.. Kafka deployments take nearly 4 times as long as other transports because of the creation of the topic an partitions. Currently all test use the same wait time whether it is for waiting for connections or file writes. So to get a CI build for kafka build would take a long period of time. The goal of the Story is to allow deployments to have a different pause time to give Kafka bus the extra time it needs but not affect the timeout for other stages of the tests.. Support configuration. Cluster Type: SingleNode Machine: Mac PR: Stream that reproduces the problem: Error Message: Stacktrace:. Spike: Produce Rabbit baseline on rackspace infrastructure. Error Started: Commit: This can be reproduced by running the test with a admin and single container on Mac OSX. Issue All Jobs fail to deploy with the following exception:. This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings. load-generator should be used as the foundation for this test with the following settings: An environment should be provisioned to support the containers, Zookeeper and Kafka.. When using the rest interface to create a Job with an empty description, used to generate the following exception, \"Definition can not be empty\". Now generates 0): Unexpectedly ran out of input^\". The correct error should be, \"definition cannot be blank or null\". XD Version Spring XD 1 Admin on own (on-metal) Rackspace machine 2 Containers each having own (on-metal) rackspace machine 1 zookeeper node collocated with admin While uting XD performance testing on Rackspace using Kafka as a transport we occasionally get the following exception: stream used to create the exception: stream create foo4 throughput\" After failed deployment. I destroy the stream and recreate it and it works fine.. When starting xd-admin getting the following exception: Reproduced Locally (mac) and on EC2. xd-singlenode works fine. Commit: 4673b5ab97. Updated XD-EC2 XD deployment for. Module delete command sporadically fails on windows. When a user utes a module delete on a custom module it sporadically fails with the following exception below at the bottom of the description. Deployment: OS: Windows 8 or Windows Server 2012 R2 Java version Java 8 (build mixed mode) XD Deployment type. XD-Singlenode (embedded zookeeper) Steps to reproduce: 1) build either the or the samples from the 2) start xd-singlenode 3) start shell 4) from the shell ute module upload for the custom module module upload processor 5) Verify that the module was uploaded by uting module info 6) Execute module delete. OS: Ubuntu Deployment Admin Server. 1 Container Transport Rabbit This should run successfully it states that the stream foo1 is already deployed. Exit shell and rerun the file. If you look at the modules deployed on the container some are still present. Note that if I shutdown the container the modules disappear.. Disable Batch Job Tests for Kafka Message Bus. Offer a environment variable to disable job acceptance tests. Enable CI Acceptance test for Kafka. When deploying XD (admin & container) using Yarn we only get the first 495 characters of the log which is the Ascii Art and Documentation links.. Create a Sink that can capture the results of the messages sent and log the number of messages received per a configured interval in seconds.. Create a loadGenerator source module. It will need to support the following Message Size The size of the message. Create a load-generator source module that will generate messages and dispatch messages to a XD stream.. When uting a Spark Application Job on XD against a remote Spark Master we receive a CNF exception for Running against a local Spark Master works normally.. When trying to configure XD to use a RabbitMQ instance other than the default a user is supposedto updated the environment variable or the setting in the file. In this case XD is ignoring this environment variable. h3. Steps to reproduce set the transport by using \"export set the by \"export Startup a admin container on your local machine deploy ticktock start up a local rabbitmq * deploy a new ticktock and stream will deploy.. Verify that network interruptions will not negatively affect the XD cluster. Verify that a container that looses connectivity will be able to rejoin the cluster cleanly. Modules will redploy when the network is back up.. must now be set in the properties file.. SHA: Deployment: 1 Admin, 2 Containers JobStore: HSQLDB OS: Mac OSX & Ubuntu Reproducible: Yes Job: job create foo \"filejdbc When using Rabbit as a transport with more than one container and launching the job above. The Job ution stays as \"STARTED\" status, even though the job is actually finished. We expect it to reach a state of \"COMPLETED\". Using Redis as a transport the job ution status does reach \"COMPLETED\". The ution step list shows: Id Step Name Job Exec ID Start Time End Time Status 8 step1-master 4 STARTED 9 4 COMPLETED. Pre-requisite for Rabbit MQ Benchmarks: Configuration changes IPerf. In this scenario I copied 2 files into the bar directory. .csv The result was that the first file was processed, but then the module deleted all The net result was that the job failed and the 2nd file was not processed.. During the slow network tests the user undeployed a stream and then immediately redeployed the same stream to get the modules on different containers. The deployment failed as reflected in the stacktrace below from the admin server, however the the shell did not report an error and the user could not deploy the stream. The Shell did not report any error. uting a stream deploy fails with the following error: Undeploy and deploy of the stream worked. INFO Deployer - Deployment status for stream 'foo': INFO Deployer - Stream Stream deployment attempt complete. XD Production support. individual container or admin .. A user should be able to ute XD Single Node as a Docker Container and have access to create streams and jobs. As a beginner (noob) docker run -P A set of instructions for beginners should be available in the of the singlenode. The creation of time log create a stream to write a file to filesystem. how to open the port this document should show how to connect to services running as docker containers via docker links: Redis relational db ** hadoop22, PHD instance.. h1. Run Acceptance tests on the following deployments. h2. Slow Network Simulate slow network by deploying a XD cluster where the ZK Ensemble is only available via WAN. h2. Network packet loss Simulate cases where a network packets can be lost.. h1. Summary User wants the ability to deploy an ec2 cluster where the admin & containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines. h2. Current functionality Currently sets up its containers & admin server to use a ZK, rabbit and redis that are provisioned and collocated with the admin server. h2. Detail The following properties will be added to the - contains a comma delimited list of zk for a ensemble. The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail. Default is - contains a comma delimited list of for a rabbit cluster. The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail. Default is - contains a for a redis instance. The application will check to see if the port is open , if not deployment will fail. Default is - user can specify the zone to which the containers and admin will be deployed. If not present AWS will decide which zone to deploy the cluster.. EC2 Environment 2524 GROUPA 2366 GROUP0. EC2 Environment log2 is undeployed and log5 is then deployed) : modules Module Container Id Options Deployment Properties modules Module Container Id Options Deployment Properties modules Module Container Id Options Deployment Properties containers Container Id Host IP Address PID Groups Custom Attributes 1045 1099 1055 1056 GROUPA 1020 GROUP0 h2. Undeploy and redeploy stream Undeploy and redploy with modules Module Container Id Options Deployment Properties containers Container Id Host IP Address PID Groups Custom Attributes 1045 1099 1055 1056 GROUPA 1020 GROUP0 undeploy foo. Update JClouds to For XD-EC2. Acceptance tests run back to back causes exception.. SHA: Deployment: 1 Admin, 1 Container DataStore: MySQL A is thrown when running the test in Acceptance tests back to back. Ran the test once. Success Ran the test a second time. The following exception is thrown: Batch Job with the name already exists The & still have job name still stored. The following Exception is seen on the admin server INFO - Path cache event: type: CHILD ADDED INFO Deployer - Deployment status for job INFO - Path cache event: type: CHILD REMOVED INFO - Path cache event: type: CHILD ADDED INFO - Path cache event: type: CHILD REMOVED INFO - Path cache event: type: CHILD ADDED INFO Deployer - Deployment status for job ERROR Deployer - Exception caught while handling event KeeperErrorCode NoNode for Caused by: KeeperErrorCode NoNode for 7 more Clear & tables and run the test a third time Ran the test a third time. The following exception is thrown: The job named is already deployed The following Exception was reported by the admin server. WARN -4 - Exception while transitioning job state to undeploying KeeperErrorCode NoNode for at Source) at Ran the test a fourth time. Success. Replace xd in hdfsmongodb with spring batch MongoItemWriter. Containers stopped responding to Admin. The log sink is not writing information to the log. Not the solution but, when is set to INFO, the log sink information is written to the log.. Log Sink is not writing to log.. HdfsTest uses the following stream to test the hdfs sink. trigger hdfs. In the test failure, the test reported that no file was created on the hdfs. I'm wondering if the trigger fired before the hdfs was fully deployed. I would say that we set the phase to the maximum, but the problem is that by default it is MAX INT. Thoughts?. Rabbit Sink & Source and are not updating module host port.. Acceptance Tests failed on the Rabbit Source and Sink Tests. The test started failing when XD-1824 was introduced (Support RabbitMQ Cluster in source sink). This story added addresses to support rabbit cluster failover. Currently if a user set to a remote Rabbit instance, XD will use the default host localhost and port 5672. However using does work.. is the only test that is dependent on an external system for its success. As such there are times that the service is running slower than the test expects, thus the test fails Once XD-1814 is merged we can utilize the \"waitForFile\" feature to wait for the result file from the stream to be written. But the wait time for twitter will be extended to 1 min. AAAAND make the the search string configurable. Some tests fail because the springio is not consistently present.. Acceptance Tests for Labels and taps. Jobs are not completely removed from Jobstore. Environment: Running on local Mac Instance: XD Deployment Type: XD-SingleNode SHA: 66c28e3 While running a test that deployed and undeployed a stream over 500 times the following exception is thrown: KeeperErrorCode Directory not empty for stream create streamfoo \"http hdfs \" Repeated the following 500 times using xd-shell Ran a script that would ute the following 25 times Ran a script to undeploy streamfoo ** Ran a script that would launch the job The logfile of the singlenode is attached.. Status on Shell command prompt is inconsistent. Deployment: xd-shell local, xd-singlenode (ec2) SHA: Once successfully connected to a server, if you connect to a server that is not present. The prompt still shows XD when it should show Can be reproduced consistently. Conversely: Attempted to connect to a xd-singlenode on ec2 using a local xd-shell. The xd-singlenode was not running. After bringing up the xd-singlenode, I was able to connect however the status did not change from 1. Bring up shell while xd-singlenode is not running. 2. Bring up xd-singlenode 3. Connect to xd-singlenode config server 1. Attempt to connect to remote server that is not available Unable to contact XD Admin Server at ' 2. Bring up xd-singlenode on remote Successfully targeted 3. Still see the incorrect prompt.. XD Deployment Type - Singlenode Required Software - XD Gemfire Sample Server After creating and destroying 3 streams with sink the 4th will fail with this error: From your shell ute the following 4 times: stream destroy stocks. & gemfireServer sinks do not close connections. Stream destroy fails to remove if the underlying modules have been removed.. In short if you attempt to destroy a stream that has had its modules removed, the destroy will fail. 1) So if I create my own and use the processor in a stream. 2) I then shutdown the admin and container. 3) Delete the from the directory 4) Restart the admin and container. 5) if you do a stream list the stream that used the is still present. 6) but you can not delete the stream because of the exception below. 1) Follow the instructions to install and use the module in a stream. 2) Now shutdown the admin and container 3) rm -rf 4) rm -rf 5) Startup your admin and container 6) stream all destroy. Then type 'y' 6a) The shell will report ommand failed No content to map due to at 6b) The Admin Server will report ERROR -1 - Caught exception while handling a request No content to map due to at Method) at Caused by: No content to map due to 61 more. JdbcHdfsTest, FileJdbcTest works for singlenode but not for admin & Container on the same machine.. Update StreamUtils based on Code Review comments.. Deploy XD Sample Gemfire on Utility Machine. Deploy stream with gemfire as a source. Create a stream (stream2) with gemfire-server as a sink Send data to stream 2 and verify that the data has been received by gemfire source. Update CI tests to increase heap, to support gemfire. JDBC Acceptance tests must jdbc props vs. configProps setting.. In this case we will use environment variables to set the JDBC sink settings. Thus we will just remove code.. After creating a composed module, I am unable to delete it. compose doo \"filter file\" Successfully created module 'doo' with type sink module compose module delete module display module info module list delete doo sink Failed to convert 'doo' to type for option 'name,' String index out of range: -1. Steps to reproduce: stream create test \"http log\" stream create simplegauge gauge\" http post \"10\" redis-cli get redis get (nil) Note: It worked with but failed only on xd-singlenode.. if user already has count in on their hdfs the input file will not copy the sample file to hdfs. need to make sure that a file is already present if the hdfs Documents have to be updated to mention that hadoopDistro needs to be added both xd-singlenode and xd-shell. 1) Update Instructions to mention for both singlenode and shell. Else demo will not work. 2) Pom needs to be updated to use at the least. 3) I can see where hdfs is writing the results 4) throws NPE Stacktrace is attached.. Batch hashtag count throws exception when launched. Need to be able setup ec2 env to test job samples. Currently in order to deploy a user created job we copy the job to the containers and admin server, and then bounce the servers. The tests will need the ability to copy these jobs to the containers, & admin and then bounce the servers. These sample jobs are located at. Move JMX Endpoints from jolokia to. Exception thrown when accessing Jolokia via the management context path. Allow user to configure tests with DI. With the addition of sinks and sources that require connections with external entities (hadoop, JMS, JDBC, the environment setup is getting unwieldy. Retrieve environment variables via Dependency injection from * Utilize profiles for single node cluster single node cluster. Environment checkers in acceptance tests should use Asserts. Replace tests and throws in the with asserts in the following methods: should check for the exact number of Jmx events instead of 0.. Add JDBC Sink to acceptance tests. Need to be able to test the following sources: TCP, HTTP, Time,. File Sink should support Replace as an option. I cannot access the JMX Jolokia endpoints using the Spring Boot RC1 and Snapshot. Works with XD-M5 and Boot-M7. JMX endpoints not functioning. Build XD-EC2 deployer from github. Should produce artifact that contains the URL container servers of the XD cluster. Application will shutdown all servers with a specific name. Application will take a parameter. Generate artifact to state success or failure. Need to update .bat files to use % for env variables instead of $. Admin needs to use configs instead of * Renamed logging file for singlenode from to. Currently HSQLDB is the only option for batch jobs. This should be configurable so that a user may select another JDBC data store option. Steps: hsql prefixes should be changed to batch-jdbc JDBC Driver needs to be configurable HSQLServerBean should be renamed to something Tests: Should be able write tests that support HSQLDB. For each of the containers: Setup XD HOME variable Copy the configurator to containers Verify that configuration files are setup correctly Report if container started. (using jmx Jolokia, if available) If it didn't start report failure but continue. Integration Testing For each container: Verify that container is working by creating a stream in admin (trigger log). Verify that the log on the container is being updated.. Copy the distribution from the shared EBS S3 the ebs volume assigned to the each node admin instance . Unzip the distribution from on the ebs volume for the instance to the home ubuntu directory ** make sure privileges are set to ubuntu not root.. Deploy distribution zip to each XD Instance as specifed by user URI. The install script steps: Setup XD HOME variable Create configurator directory Use port watch to make sure they started use port watch to make sure the admin started on 9393 Report public DNS name of admin-server Verify XD admin has been started Query the redis to see if the stream was created.. Install XD admin instance on EC2. TBD. JClouds itself has extensive testing, can look at those for structure. Verify ports are open Instance Information Report successful and failed Instances * Allow user to send in a JCloud script to boot strap server.. Create google doc with instructions on managing EC2 Instances. User requires wiki page on how to use the XD EC2 Installer. Here is an example: the following request for streams: Returns: This XML file does not appear to have any style information associated with it. The document tree is shown below. Could not marshal PagedResource , links: : null; nested exception is - with linked exception:. Rename source-config to All xml files should be prefixed with test. testsource, testsink * Make sure all tests pass with new configuration. User wants to be notified when a exception is thrown in a module. Create an error channel that a user can tap into to receive failures for each module. The payload of the message will be the message that failed. The header will contain the exception information. Possibly have an error channel at the stream level?. Offers the functionality to make http request to a web service. outbound http gateway. Example stream create foo \"trigger rest stream create foos \"trigger rest log\". Add a Processor for Restful webservices. Parse needs to handle a embedded in a name.. Trigger can send a message to a named channel. For example: trigger create mytrigger \"trigger ' Luck, we are all counting on you'\" foo Where the contains the message that will be sent to foo job component.. When creating a job, a named channel will be created with a name of job. Required components: - A Transform See XD-733 - JobPlugin needs to create the NamedChannel for the job and associate the transform. will need an input channel? Name channel support will be required. - Add to job rest apis to notify system that a named channel is requested. *Unit Test. Modules need to validate their parameters at create time.. Also, if you deploy the Job it will fail, but then you can't delete the job.. Cron Jobs stop firing when a named trigger is created and deployed. 2 options are: 1) Fire the trigger immediate - Launch the job when trigger can gather the resources necessary start the job 2) Do nothing - Ignore this job fire time and catch this scenario can occur if XD is down or resources (threads) are not available at the time a job is to be launched.. Document Splunk source sink. Handled by 1245. After reviewing the code this weekend I identified that we had not created a job definition repository, just a job repository.. ", "contenttype": "application/json", "created": 737603, "id": 8, "language": "en", "user_name": "grenfro", "email": "Grenfro@gopivotal.com"}]}
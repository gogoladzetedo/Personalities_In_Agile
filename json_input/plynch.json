{"contentItems": [{"content": "add log message if the data directory bundle cache contents are updated with new bundles. We are asking persons to install a patched osgi bundle and either delete the data cache directory or add a clean cache file. Then we may get a response the patch didn't work. We are left wondering if there could have been a mistake removing the cache directory but we have no log message to verify. One might get confused about where the data directory is because there also may be a data directory in the install directory as well. h3. Expected - a single log line at INFO on Nexus startup that summarizes that the cache directory was updated with bundles. RedHat docker push HTTP PUT uploads tar content instead of gzip and triggers 400. These commands can trigger Nexus to return a HTTP 400 response while reading already stored docker blob data. docker import docker tag docker push To review, Docker Client is submitting a JSON payload as part of PATCH requests that Nexus stores into blobs - at the end of all the chunked uploads, the docker client tries to end the upload with a HTTP PUT request. The PUT request of zero (0) content fails when the blob data is read from disk on the Nexus side. Nexus is working correctly with docker client using the same commands. Also Nexus 3 m7 and m6 was working with docker client with the same commands. Nexus was upgraded from a Nexus 3 M7 data directory. Redhat (OpenShift owner) is requiring the version of docker as part of the OpenShift platform. Docker requests fail with this pattern: - bakersi \"PATCH 202 0 12166 - bakersi \"PUT 400 192 564 Notice it is the PUT that is trying to complete the upload and sending 0 content which fails. A closer look at the stack trace tells us that Nexus fails when it tries to parse the content already stored inside uploaded blobs. So in some way nexus should try to report more precisely the actual problem or prevent getting into this state in the first place. h3. Workaround At least one of: - upgrade to a newer version of docker - - upgrade to a newer release version of Nexus that contains the fix. Generating support zip with configuration requires access to Nexus is tryiing to contact which is the main Eclipse web site. With external internet access blocked, Support zip generation (with configuration) fails with the following: h3. Expected - when generating a support zip, generation must not fail if external network access is not available - do NOT attempt any external network access when generating support zip. prevents installing gems when Nexus is running on Windows. improve logging when a retry is made in response to remote socket exceptions. REST client does not properly handle packaging parameter. Per NEXUS-4115, Nexus needs to allow case insensitive userid matching. There is a bug in nexus 3 LDAP user role mapping where this fails. Create an LDAP configuration as in the attached screenshots and map an LDAP user with 'test0002' user id. Assign the user the nx-admin role. You can successfully authenticate with this user as expected with , , or , however the roles are not mapped correctly unless you use the exact case userid that was mapped `test0002`. This results in being able to signin into the UI using any case, but not seeing the Administration cog or getting any admin privileges unless using an exact case match to . h3. Expected Correctly map all roles to a successfully authenticated user.. Tar does not contains rebuilding metadata for some npm packages. I have a pair of npm repository. One of them is a proxy repo to Other is a hosted repo, that is a mirror of the first. Artifacts from first repo is copying to the second. And than I build metadata on second hosted repository I see error, that some artifact Tar does not contains (see attach) What else, if I unpack a pair of artifact, I can see that they have different structures. - I can see on hosted repository, - I couldn't see and have error INFO - - Failed to extract or malformed from. Nexus had a single log line you could grep for Nexus startup AND determine the edition being started. OSS PRO Now the edition is no longer present and there is no simple way to determine which edition of Nexus the log is from. In both editions print this: h3. Expected Support staff need a way to quickly determine the edition being used only based on a single line of the log file. When this is especially important is during startup where errors may prevent getting a complete support bundle. h3. Workarounds - look at the plugins being loaded ( one per plugin) - from the reduced number of these log lines, one can guess that OSS is being used. - grep for and look at the app directory - the path printed at that line may include something like instead of h3. Other Ideas If the new line format must be kept, add a new log line with the text \"Nexus Pro\" so that our old method of grepping for edition can work.. UI javascript files are not. licensing UI should show distinction between recent connections and total licensed users. expire cache task on rubygems repositories may lead to api performance degradation. URL in proxied yum metadata files is not rewritten. h3. Reproduce Configure the following: rubygems-group - rubygems-proxy ( - ) rubygems-proxy is configured with Artifact Max Age: -1 Item Max Age: 1440 Configure logger at DEBUG level. Request a gem file through the group found on curl -u -o dev null -v This should return 200 response with correct content, and nexus should go remote since it does not have it cached yet. Confirm the file is now cached at Make the same request again. Nexus goes remote again for the same file. h3. Expected Since Artifact Max Age is -1, and the gem is already cached, Nexus should not go remote again until the actual gem file itself is no longer in the proxy repository cache or the max age for the specific gem is expired. Nexus should always check local first and serve it if present in storage. Once found, it should not continue to check any other member repositories of a group for the same gem. Make sure Artifact Max Age works when the proxy is accessed directly also, or there is an equivalent request which requires resolution of the specific gem file requested.. The Nexus Basic Auth realm name changed in version due to unintended branding changes. This could affect some use cases where the exact name of the realm was depended on, so we restored the original name to \"Sonatype Nexus Repository Manager\" Related issue:. revert Basic auth realm name change introduced in. h3. Problem If a user is not granted the Staging: Drop Repository privilege, they can still drop a repository upon release of that repository using the resource. h3. Reproduce Configure a user `sonatype` with UI Basic and a custom staging role: The user can login to the UI and view the staging repository list. The Drop button is disabled, implying they do not have the drop permission. However the Release button is not disabled as expected. The Release confirmation dialog includes a checkmark to Automatically Drop a repository upon release. When selected, the repository is dropped upon release, despite the user not having Staging: Drop Repository privilege. h3. Expected The bulk promote resource should only perform the release if the drop checkbox is not selected ( payload implies do not drop) when the user does not have permission to drop a repository. The UI should display a permission error. Keep in mind the maven staging plugin also uses this resource.. all proxied repository items should have \"remoteUrl\" attribute set. If you configure a port on a docker repository, you can also access the rest of Nexus through this port, including the UI. You can also configure the port to be the same as an existing connector defined manually in You cannot configure the port to be the same as another docker repository connector. Regardless, this is much more access than a docker specific repository port implies. Suggest we limit accessible URLs through a docker repository port to only those known to map correctly to docker repositories. Alternately, do we have a use case for allowing to use the same port as one configured in the jetty configuration files manually? The only benefit might be that one might want to reduce the ports to be managed through firewalls. However does this lead to potential exposure to URL conflicts with other parts of Nexus?. installing gems with long dependency chains can trigger IOException File name too long. Using bundler in particular, installing a gem through a rubygems proxy repository in Nexus can cause Nexus to return a 404 response and print File name too long in the logs.. allow setting for LDAP connections. At Under the valid names section: So Nexus needs to support package names like this when requested. The rule: \"package name must not contain any characters (since name ends up being part of a URL)\". valid npm package names not unescaped properly. deadlock between mergeropo and staging promotion. unable to start nexus when is set. help text in routing rules is wrong. remove codehaus snapshots from default configuration. orientdb may not fully recover from a restore process due to Class 'OUSER' was not found in current database. Yum updates to build promotion repositories are not propagated to their parent group repositories. please confirm - are you or are you not seeing this daily on Shall I delete your comment that you are seeing this daily?. outbound http connections may be immediately closed on 304 response with ETAG instead of pooled. archived name format should be more easily recognized as a log file. Our request logs log by default using the 'common' pattern: The field prints the response time instant. Example: - - \"GET 404 657 When correlating when the request is first received ( useful when coordinating requests with builds or other external scheduled jobs, it would be helpful to determine the elapsed time of the request from the request logs. This can be accomplished by using this pattern in We should adjust the default request log pattern to include elapsed time.. releasing a yum enabled staging repository overwrites yum metadata in release repository. outbound ssl sockets do not timeout if the remote does not respond. Bad things can sometimes happen during a Nexus shutdown process. Usually Nexus is restarted soon after. A support zip includes the Nexus intialization time start time. However if something bad happens during shutdown, it is sometimes useful from examining log files to know how long Nexus had been running just before the shutdown. These messages are currently printed on shutdown start: This is a request that as early as possible ( perhaps as part of the rather generic \"Destroying\" message ), Nexus also print a log line on shutdown initialization which indicates the total 'uptime' Nexus had before being asked to shutdown. Something like: \"uptime 11 days 12 hours 13 seconds\". This way, we know what log files to look at for the last Nexus startup before shutdown.. improve robustness to orientdb shutdown after stopping the store. The attached log shows a graceful shutdown on Windows and a message about a corrupt OrientDB because the file was zero bytes. There's a potential flaw in the NPM shutdown logic where an exception while stopping the store means we don't go on and cleanly shutdown OrientDB: This doesn't explain why the state transition failed ( in the attached log ), but adding a block here should avoid leaving OrientDB in an odd state when it does happen.. logger prints useful outbound request information in a compact format. One useful addition to the log message would be the response http status code. This can help detect remote problems more quickly, and can help infer what why Nexus responded to an inbound request. Additionally, the npm plugin should log outbound requests in the same format as other proxy repositories do.. logger should include http response status and have consistent format. can have performance implications with large numbers of repositories. outreach does not detect http global configuration changes. add useful logging for resource username mismatch. gradle sample project uses an obsolete version of the. On every npm proxy repository cache expiry, when the remote is checked for metadata updates, then the npm Orient DB database file file grows by a large unexpected amount. In theory I would expect no need to store this much new data in the database for something that did not really change. Reproduce using 1. create npm proxy repo to 2. Set all cache settings to 1 minute ( for testing purposes ). Save. These will display as 1,0,0,1 ( UI bug, not the issue ) 3. note size: mine is 65k 4. request and get 200 response 5. note size: mine becomes 449K 6. wait more than 1 minute for cache expiry. Set logger to DEBUG. 7. request express again - verify 304 not modified response from remote, note size increase - now size is: 833K 8. repeat - for every cache expiry, will grow over 400 k.. improve snapshot remover tasks performance by reducing potential i o. 1. When processing GAV that contains multiple timestamped pom files, and the remove if released option is true, then make sure we only check for release once, not once per every timestamp snapshot. This reduces the I O for the task when the remove if released option is checked ( true ) . 2. Do not include signature or hash files when checking for the oldest accessed snapshot last requested timestamp. Given each artifact can have upwords of 5 total of these , .sha1 and .md5 ) and typically always two ( .sha1, .md5 ), this can reduce I O reading attributes files by a minimum of 66%. This is always a benefit to the task because this task always tries to calculate the days since any snapshot was last requested. It does this by reading attributes files off disk. Avoiding the above files means attributes for these files does not need to be read off disk. 3. When determining the most recent last requested time for the snapshots in the same build number, avoid iterating over the entire GAV collection of files for each artifact to check. By caching the last requested timestamps in the main processing loop, and determining the most recent last requested date on the fly, we can avoid iterating over the entire collection again for each file, when needing to find the most recent last requested for similar snapshots. This has significant performance benefits for the task.. See video: Note I am not clicking anything other than the Create Role button. Menu is just hiding on it's own before I can click anything.. mime detection may not cache properly for specific request paths. non proxy hosts tooltip suggests a misleading syntax. At the moment we always merge the downloaded package root with previously cached content. This can end up leaving bad entries in the cache even after they have been removed from the upstream proxy. The most likely reason package versions were removed from the remote is due to the package author them. End users should examine the associated package SCM repository commit history to look for a note of such an action. NEXUS-8625 also describes another scenario where Nexus can end up with bad metadata. Expected: Replace the cached metadata content with the new downloaded content.. Our current npm repository behaviour: 1. Request a package tgz through a proxy repository that exists in the remote. 404 not found 2. Request the metadata for that package. 200 response and package url in step 1 says to get it from Nexus 3. Try to get the package again from Nexus - still 404, cached not found. Expected: Nexus should try to be more forgiving when a package file is requested before metadata.. prevent when expiring not found cache and updating package metadata at the same time for a npm repository. The npm database can get in a state where expiring the not found cache on an npm repository can trigger an if package metadata is updated at the same time by another thread. The other thread would typically be a get or PUT request for an npm package. Expected: do better preventing this commonly reproducible concurrency issue. expire cache task on npm group repositories should not abort when there is a problem processing member repositories. ExpireCacheTask on an npm group repository will abort if there is a problem processing a member repository. Expected: The task should not abort. The problem should be logged and the task should continue processing as many records member repositories as possible. For an example problem, see NEXUS-8568.. Under certain startup conditions, Nexus staging configuration validation can orphan staging repositories such that they are no longer visible in the Nexus Staging Repositories UI. The repository storage directory will still exist for the repository, and the orphaned staging repository(s) will still be visible via Repositories - Nexus Managed Repositories list. Example log excerpts on startup where staging validation removed a staging repository because it was not yet added to the internal registry of repositories: h4. Symptoms After a Nexus restart, some staging repositories are no longer visible in the staging repositories list. Log messages similar to this will be present in - Validation warning: o repositories - Staging Repository is not a valid repository, removing from configuration. h4. Workaround There is no workaround to prevent this race condition. h4. How to Recover Orphaned Repositories. Repositories can be recovered by Sonatype Support. Affected users should open a support ticket at along with a Nexus support bundle.. not found cache should be expired for packages with implied references from updated package metadata. deprecate and disable the \"download nuget feed\" scheduled task. Start nx3 for the first time. empty storage. Add an HTTP proxy to Nexus. Trust the SSL certificate my proxy serves using the SSL Certificates UI ( this works fine and goes through proxy) GET Request is 200 and works, but request does not go through proxy server tested. nexus pro log may report nexus as unlicensed on startup even when it is. make it easier to find the nexus software license. It would be useful to get ?describe output as JSON in addition to HTML. - scripting can parse JSON much more easily than html - when requesting ?describe output from an end user for asking the user to login to UI, and then using same browser session to request ?describe output is extra work to do and explain. In some cases, the user may not even be able to access the UI due to security restrictions - it is much simpler to visually grok a JSON response on the cmd line - a cmd line response as JSON can be more easily piped into JSON parsing tools to isolate specific data Proposed Criteria: - if the user agent implies a web browser is being used, return html, otherwise return JSON with the appropriate Content-Type header - if the request Accept header explicitly requests either JSON or HTML, return it as requested - the data (model) returned for both content types should be identical - JSON pretty printed by default is preferable, but not absolutely required initially if it impacts the implementation significantly. Connection leak in Browse Remote when content encoding is gzip. There is a connection leak triggered when using the Browse Remote feature. h4. Symptoms Logs contain these types of messages: bq. WARN - - Failed to get directory listing content bq. Timeout waiting for connection from pool h4. Cause Under normal circumstances the leak is handled gracefully by GC and HttpClient. Still, in case when remote uses gzip and or chunked transfer encoding, the connections are NOT reused even after longer period, leading to connection pool depletion. h5. Original reporter's description: When I'm browsing a remote maven repository in after maybe steps through the remote repository tree, I get an infinitly spinning cirle. Refresh doesn't work either. The only way to continue browsing the repository is to restart Nexus. This seems to impede all communication with the remote repository. Downloading a file that has not yet been cached locally doesn't work either in this state. h4. Workaround For immediate mitigation a Nexus restart is required to free the leaking connections. For temporary mitigation until you upgrade to a fixed Nexus version, install the version specific patched jars attached to this issue.. Create a Maven 2 proxy repository to called `Yum-Newrelic` a request at this path is uting ( and ultimately returns with 302 or 404 ): before this request ends, a request at these paths at the same time fail or throw errors:. concurrent request paths cause during population of not found cache. support zip generation fails if system has mounted clearcase volumes. The forgot feature rest resource ( ) of Nexus can cause performance issues against an external realm. We should consider options such as: - optimizing the generic queries that the resource performs for external users - provide a configurable way to disable the feature - consider removing the feature entirely if that is easier - removing the Forgot Username and Forgot Password resource privs from the built in anonymous role. Acceptance Criteria: - Remove Forgot feature from UI (just remove the js code). forgot password feature performs badly with external realms. Create a npm hosted repo with id 'npm-hosted'. Publish one package into it. Hit the - all resource for this repo. Verify the published package metadata. Delete the entire npm hosted repo using the repository Delete button. Create another npm hosted repo with the same id. Hit the - all resource for this repo again - you still get metadata about the first repo even though the new repo contains nothing. Similar: delete all the content from a hosted npm repo but leave the repo itself. Nexus still serves metadata about packages which do not exist. Expire cache on the hosted repo does not help.. Tried to run rebuild hosted npm metadata task ( new in ) against about 500MB of tgz packages from the strongloop registry. Had several messages of concern - unsure as to the overall seriousness of each of these:. Enable User Token and the Protect Content feature. When a request is made to a content path with valid credentials that are not Nexus user token credentials, Nexus responds with 401, but no entity explaining why. Problems: - the end user is confused, because they know they have entered technically valid organization credentials. - the Nexus admin is confused because they either have forgotten about or were not the ones who setup the Protect Content feature, or just assume protecting content is a good idea, so leave the box enabled. - the Protect Content feature is valuable, but it is a rather odd special case that affects all realms in Nexus because of the special Token it creates internally, so an administrator is not reminded it may be in play because it is not near where all the other realms are configured - a Nexus admin must enable DEBUG and TRACE logs to see why there was a 401, assuming they can even understand what loggers to enable and what to look for Improvement: Simple continue to respond with 401, but include a simple message body explaining the reasoning - that user token credentials are being enforced in Nexus. In this way a simple test using curl that gets 401 response will help the admin, end user or Sonatype Support in quickly identifying the problem.. maven site deployments with .. in paths fail. support proxying. resuming downloads for unsatisfiable Range should respond with 416 or 200 instead of 206. Currently a request to logout with a valid session cookie, will delete the server side session in Nexus, so that the originally sent session cookie value is no longer valid in the browser. However the response that comes back should ( but does not ) ask the user-agent to delete expire the existing session cookie, so that it does not bother trying to send it again. We should make logout return a Set-Cookie header as expected that forces delete expiry of the session cookie.. should ask the user-agent to delete the session cookie. allow nexus to load outreach content by and user. Secure flag should be set on Set-Cookie values dynamically based on if the inbound request is reported as secure by the container hosting Nexus, instead of using the configurable option provided by NEXUS-7800. Configure repos: nuget-group ( ) Delete the Nexus anonymous user. Do not configure Nuget API key realm. Make the following request with Nexus wget admin -S by design, wget does not use pre-emptive auth and makes two requests, the first responds with 401 and headers and the second sends your credentials in response. does not print the authenticated user on the second request. - - \"GET 401 0 - - \"GET 404 388 Note: the 404 in this case was because I had an http proxy server configured in Nexus returning 404 for the outbound request. This should normally return 200 and not related to this problem. Seems like the security filter change in NEXUS-7785 where the logging was added is not being picked up for some reason.. As a Nexus administrator I want a supported procedure to rebuild the npm metadata from existing npm repository storage, particularly from hosted repositories. This is useful for rebuilding metadata from rsynced npm storage in a failover instance and as a database corruption recovery tool.. provide a scheduled task to rebuild the npm metadata from storage data for hosted repositories. non-snapshot versions containing SNAPSHOT can bypass a release repository Deployment Policy. npm groups should merge versions of the same package in different members. in pom validator staging rule. capture generation time in analytics event-zip as reference. limit size of analytics event zip files at creation and submission. downloading specific versions of NuGet packages via Visual Studio package manager console fails. Upgrade to Apache Tika for better mime detection. The clm server password is not removed from the file in a generated support zip:. npm install cmd can trigger nexus NPE and 500 status when remote returns non-standard fields and stub attachments. Configure proxy to Configure proxy server in nexus. Make these requests: curl -s -v -4 gets 404 curl -s -v -4 gets 200 but nexus sends TWO requests to remote - see NEXUS-7616 ( this creates a file at ) cat bower jvm 1 INFO admin - Applying Nexus Configuration due to changes in made by jvm 1 INFO admin - The Remote URL of repository \"npmjs\" (id npmjs) has been changed, expiring its caches. jvm 1 INFO admin - Scheduled task started :: Expiring caches for repository npmjs from path null and below. jvm 1 INFO admin - Scheduled task finished :: Expiring caches for repository npmjs from path null and below. (started runtime jvm 1 INFO admin - Applying Nexus Configuration due to changes in made by jvm 1 INFO admin - Applying Nexus Configuration due to changes in made by jvm 1 INFO admin - Saving model jvm 1 INFO admin - Saving model jvm 1 DEBUG anonymous - CookieSpec storage!, caused by: Could not create the directory hierarchy in repository \"npmjs\" to write caused by: Not a directory jvm 1 DEBUG SYSTEM - Close connection. programatically enforce minimum requirements for yum configuration including debug messages. In NEXUS-5526, a change was made to allow system properties to be set on the HTTP Client embedded within Nexus. We have since regressed back to not allowing this: And the attempt to backout changes did not restore use of the System connection factory method: In Nexus we started including httpclient into Nexus. - however in our regression prevents setting protocols and ciphers on outbound connections from being an option for end users. So two problems: - it seems honouring system properties that influence the outbound http connections - we don't expose a way to set https protocols and ciphers preferences on Nexus outbound connections ( ) Expected - make Nexus use the system socket factories provided by http client, so that standard system properties can influence outbound connections. allow configuring and on Nexus outbound HTTP client connections. Show \"Browse Storage\", \"Browse Remote\", \"Mirrors\", in \"Summary\" tab based on repository type. h3. Browse Remote Browse Remote parses remote HTML directory lists. Unless the remote publishes a parseable HTML directory listing, Browse Remote cannot work. Browse Remote should only be visible for Maven 1, Maven 2, P2, OBR repository types. ( although as stated, if remote is not publishing something parseable, still may not work ) h3. Browse Storage Show \"Browse Storage\" only for 'maven1', 'maven2', 'nugett', 'obr', 'p2', 'site' In the case of P2 proxy repo, the UI may timeout requesting the local storage contents, as the local storage triggers generating of a large which can take greater than the 60 second default UI timeout to render. h3. Mirror Show for hosted repos only for maven1 and maven2. h3. Summary Tab maven1, maven2, site. npm hosted repository should maintain \"time\" field on deploys. If I am a savvy user and am using over HTTPS, and issue a metadata request like this one: It will tell me to get the tarball over HTTP. What is the point of HTTPS then? As I checked, both HTTP and HTTPS URLs works for tarball. NPM registry issue was told to close it, then we filed was told to close it, then we to get some traction.. comma in group membership attribute value breaks static LDAP group mapping. maven staging plugin -1 on release using Java 8. and master branches have been updated A note that we are justifying this change because the NuGet features have moved into OSS recently We expect the host resources available to OSS users to be similar to pro users now as well. Specifically the heap sizes are changed as follows in. Configure ldap config to a valid server with 5000 users. Open users management. Change the source to LDAP. Nexus now makes 5000+ group member queries and tries to load 5000 records into the Nexus UI. More than likely Nexus UI will timeout and not render anything - meanwhile the queries are happily proceeding as requested in the backend. This will either crash LDAP, crash Nexus or crash the browser.. prevent from creating sqlite rpm metadata. NEXUS-6189 introduced not returning headers for 401 web browser content responses. This is non-standard behaviour. A customer wants to upgrade to latest Nexus, and when they did, this broke some internal tooling that relied on Disabling the browser detector is not a good long term solution for them because their internal tool is already deployed to production. The request is to add some way to specify a user agent string that can always be treated as a non-browser, and therefore return the default authenticate headers.. Summary: - TMPDIR environment variable should be set to absolute value when YUM command line is forked environment*. Yum createrepo and mergerepo tools seem to respect the TMPDIR environment variable. Launch Nexus with TMPDIR environment variable not set but system property set in property. When a YUM metadata task is forked, the forked yum tooling can potentially choose a different tmp dir than what is set as. In one case this caused a no space left on device error when metadata was being generated for a large yum repo because var tmp was filling up. Additionally, our YUM code makes assumptions about the tmp dir being used by YUM, which could conflict with the tmp dir specified by TMPDIR env variable.. . start (no output to console - did it start?) . start (no output to console about already running container) now you have two containers running and no feedback about this . stop (no output anything was stopped) You still have one container running. Continue stopping by running . stop - sometimes the script does detect the other containers running, sometimes it prints Can't connect to the container. The container is not running. when one is Same thing happens using . nexus script directly. Expected: - prevent starting multiple containers - properly detect running containers - always provide feedback to console about what we thought happened - do we even need all these individual control scripts exposed to user? what about just having like before. running . start n times, starts the container n times. Yum metadata for proxy repositories should refer to the URL of the source Nexus instance. add more robust proxy repository URL validation. upgrade from previously upgraded OSS to Pro ldap configuration can fail subsequent upgrades. LDAP OSS to Pro upgrade bug, multiple configuration fields are not migrated. allow direct request for NuGet artifact through proxy repository if artifact is not already cached in the local feed. Nuget: return 403 with reason instead of 404 when redirection fails through a proxy server. Given an org configures an http proxy server to access certain hosts only And Nexus is configured with this http proxy server And GET requests to a nuget proxy repository hosted in Nexus have to follow a redirect to a different host than the host they proxy in order to download an artifact When the artifact is downloaded through Nexus and the http proxy server responds with 403 because access to that host is not allowed Then Nexus should respond to the original request with 403 And the response should include the possible reason of the 403 ( source proxy server was used, the redirected to host used and that the routing through it failed with 403) Nexus currently responds with 404 and no reason to the NuGet client. This leads a Nexus admin to turn on Nexus DEBUG logging to see redirection failure instead of client user knowing they need to configure the Nexus HTTP proxy server to allow certain hosts.. Crowd plugin that is not configured logs when viewing security roles. CLM application drop down when editing a staging profile has some confusing items. - it asks to choose \"(none)\" when it is not even an option if CLM is not configured. - it asks to \"select an application\" when one can't be selected since CLM is not configured, OR the license prevents display of an app OR CLM user does not have permissions to the app.. upgrade to HTTP client. Smart Proxy download immediately option for checksum updates sends duplicate download requests for main artifact. OBR virtual repository metadata update fails when triggered by smart proxy download immediately. uncompressed archives with HTML file as an entry can be rejected by file content validation. Archive browser doesn't work for NuGet .nupkg packages. ERROR log message from M2Repository - does not include root cause throwable. Nexus logs may contain an ERROR log message similar to the following ( not specific to this particular artifact ): ERROR anonymous - Got in proxy repository \"Atlassian\" while caching retrieved artifact got from URL will attempt next mirror, cause: Cause: Expected: This log message should include a stack trace to better understand what led to this problem.. A comment with security level 'Developers' was removed.. inbound request URL syntax validity should be checked and fail fast. Inbound request URLs that contain certain invalid characters may bypass basic syntax checking and cause Nexus to perform more internal work then necessary. This can also cause Nexus to report noisy WARN messages in the logs. Expected: Nexus should perform URL syntax validation as early as possible and fail with simple log messages instead of verbose WARN when a URL is syntactically invalid. The HTTP response should return a 400 status in this case.. Enter as the search term for the key and value fields in metadata search. You get an ugly error dialog in In the error dialog is less ugly although the error message could be improved to be less technical. The 'home page' link in the error dialog is broken. ( 404). I tracked this down to cookies do not typically set the port. So per RFC can be sent to a different server as long as the host name is the same. Setting the port in the cookie may cause other issues with browsers (and how does this play with firewalls and proxies) One simple solution is to make the cookie name configurable. If we ever switch to shiro-guice (which will remove a bunch of other code) we could easily the cookie name. Or if we are going to keep our boiler plate code, we could configure the cookie name in to call Original Setup: I started two nexus pro instances locally. Nexus A - - publisher Nexus B - - subscriber Established a Smart Proxy trust between A and B. Created repo on Nexus B proxied to Nexus A Besides logging into the UI only a few times I noticed the following after a short while in the Nexus B logs: jvm 1 INFO - - Validating all active jvm 1 INFO - - Finished session validation. sessions were stopped. Nexus A seemed to have 169 sessions cleaned up. How is it that 274 sessions were created? Are these being created by smart proxy?. Enhancement: Tie OData to Lucene index (for performance). Create a Nuget Repo Group containing one each of Nuget Proxy, hosted, virtual repos. Create an Expire Repository Caches task. Notice that the NuGet proxy and Nuget Hosted Repos are available to select in the task configuration, however NuGet Group is not. Compare this with the fact a Maven 2 Group Repo can be selected for this task.. Enhancement: Browse Index tab for NuGet repos. Given that a user can browse an Index of Maven artifacts via the Browse Index tab, and given oData information may be made indexable with lucene in Nexus UI, it may be suitable to support a Browse Index view of nupkg artifacts from within the Nexus UI. The usefulness of this may be in question for NuGet repos however since developers will typically use NuGet Package Explorer to 'explore' nupkg artifacts.. Not having JCE cause problems with some installation We should detect if it is installed, and if it is installed, log the fact at INFO. Apparently calling this will work for this purpose: It will return 128 if no JCE is installed, 2147483647 if it is.. Print message in log if high-strength JCE is installed. If yum metadata generation fails the output of the command should always be logged. The support tools tab does not show how to contact support. The edition should have a link to the \"create ticket\" link in the support site (. Add end-user instructions for support ticket creation in Support Tools UI. nuget local repos feeds should support nuspec dependency optional attribute. Nuspec defines an optional attribute as of version When uploading a nupkg with a nuspec containing this attribute, Nexus does not expose the framework bits in the feed element, therefore . In contrast, . Example: 1) Download a nupkg which specifies dependencies with Results in a file called 1) Boot nexus Pro 2) Add a local repo of Nuget type 3) Using the artifact upload tab, upload the nuget artifact into the local nuget repo. 4) Perform a search against that local nuget repo for the uploaded artifact. The feed entry returned will not contain the string inside the dependency element. Compare this with a proxy Nuget repo of the official feed: 1) in nexus, add a proxy repo against 2) wait for the download nuget index task to complete ( approx 5-6 minutes ) 3) Perform a search against that proxy nuget repo for the same artifact. The feed entry returned will contain the string inside the dependency element. Attached files contain the detailed differences: curl -v \" -o -u curl -v \" -o. Starting in Nexus automatic upgrade of versions of Nexus older than are no longer supported. Upgrades to Nexus or newer must first upgrade to the latest version first, then upgrade to the latest version.. ui dialogs display literal html tags. make a UI request to Nexus that will timeout. the simplest is start nexus, login, shutdown nexus and make another ui request. You see a dialog that states the request timed out ( as expected ) but the message starts with '' This is just one example. Other dialogs have the same escaping problem.. improve Remove Releases from Repository task performance. As said in summary. When first scheduled, we had an oom exception. So we increased the max memory to 1 GiB. After that we had no more oom issues. The task ran for 147h 43m 57s and finished successfully. During this time he cleaned up 8270 releases (as derived from the log entries \"Recreating Maven2 metadata in repository ID 'releases' from Disk space went from 134GiB down to 75GiB. While it was successfull I think this is incredibly slow. The fix might be similar to the one from issue NEXUS-4640. Fix: A new task option is added to make the task perform better.. Seeing this a lot in customer logs. Can we prevent this huge stack? Looks like request was ending in 4xx error and failed to write the template. Hopefully it cleans up after. Browse remote tab is visible for Nuget repos but should not be. To minimize any potential problems fronting nexus with Apache mod proxy or other reverse proxies using the headers, we should configure Jetty to acknowledge and respect any X-Forwarded headers by default. See Jetty Logic here: See Jetty Docs describing how to front Jetty with reverse proxy SSL: Related forum post: We should also update the book to mention how to set the header in httpd as well.. Role ID field should not appear editable after save of External Role Mapping. DN values containing \",\" (comma) can result in improperly escaped LDAP filters. improve SNAPSHOT version detection when deploying release artifact to SNAPSHOT repository. Nexus upgrade does not properly back up changed configuration files.. Regression: Failed. Revert: Link to nexus book logging section in the logger UI. When setting \"Publish URL\" to false, prevent repo Summary tab from displaying 'undefined' distribution management section. Nexus is generating invalid at GA level. in your local hosted releases repo create the following paths: start Nexus if you haven't already. Login as admin. Browse releases repo local storage. You should see the file paths above. right click on each one and upon request. Also notice the '(Not Found)' text appended to tree paths when selected in the tree. See attached video for overview. behaved slightly different, finding more paths, but also returning server error for the one with percent sign, where simply says Not Found.. I tried adding a unit test to in ldap-common module. Since all the unit test methods are using Junit 4x annotations I assumed these were being used to run the tests. It turns out that this is not forced ( it used to be afaik ) and instead Junit delegates to instead since in above case depends on from which extends PlexusTestCase which finally extends Junit 3x TestCase. Surefire decides that Junit 3 runer must be used then. This leads to confusion in writing additional tests and who knows if some test methods are not being run because they are not named properly. Test set: Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: sec <<< FAILURE! Time elapsed: sec <<< ERROR! No roles found for user: cstamas Method) at Method) at. hanging test using Jetty 6x windows. Noticed was hanging for 11 hours and took a thread dump of the stuck surefire process.. Only proxy repositories should participate in not found cache (NFC) to improve performance. We should log this at DEBUG:. If a capability is created and then encounters a configuration error, the description will contain the word FAILED: followed by the class name of the see NXCM-3681 ) When trying to delete the capability you will be asked for confirmation with a message such as \"Delete the \"FAILED: capability?\" It would be more logical to use the capability type instead of description here, or neither of these. See attached screenshot for an example of how this looks.. Attributes Upgrader logs duplicate stack trace when a file is not found and stops. Index: 2, Size: 0 editing group membership. This was seen running the load test described in NEXUS-4744 h3. Variations of the same theme. While exercising a load test of sorts on Nexus, I got this exception trying to deploy artifacts. The following simulation was running: 30 users fetching artifacts from releases 30 users deploying artifacts to releases 10 users deleting artifacts from releases 10 users adding and removing releases repo from public group repo 10 users expiring NFC cache of individual artifacts in releases repo Up to 100 users were also requesting uncached artifacts via a proxy repo for 'releases' on another machine. Nexus had smartproxy installed, but disabled. The releases repo configuration was as below: Let me know if you want the test code. h3. First Exception in logs ( maybe related to adding and removing repo from public group ) h3. Second Exception further down looks like it was the put causing the real problem.. Create a Synchronize Shadow Repository. In the repository selection list, all repositories are shown - however this task only applies to Virtual Shadow repositories. Expected only the repository type that applies to this task to be listed. setting up the task against a repo that does not apply does no harm - those repos are just ignored.. Local Timezone description should be displayed in screens editing times of a scheduled task. docs indicate wrong result type. Hosted maven-site repository summary Distribution Management section wrong - refers to. make default value of Publish URL \"True\" when creating a group repository. Information unnecessarily logged as ERROR when repository put out of service. repository CYCLE detected log message is misleading. Authentication error shows up as \"400 bad request\" during smtp validation.. ", "contenttype": "application/json", "created": 737603, "id": 62, "language": "en", "user_name": "plynch"}]}
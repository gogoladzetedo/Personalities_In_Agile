{"contentItems": [{"content": "Add support for Tuple and JSON SpEL property accessors in. As a user, I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.. Consume environment variables at ModuleLauncher. As a developer, I'd like to pass any level environment variables, so I can use the tokens at runtime for binding the launcher's own boot properties, such as remote maven repository locations for module resolution.. The following commands should work: task status should return one of: launching cancelling failed * completed. after successful creation lists the stream after (re)creation deploys the stream (verifiable in the Admin console) * will fail, only because the does not yet support that. For this issue, verify that the stacktrace shows the delegation to (the Admin will crash at that point, so try it last). As a developer, I'd like to use an in-memory stream definition repository, so I don't have to spin up a store; obviously, this will not persist between application utions, but it will be useful for a simplified development experience.. Add in-memory stream definition repository. * stream can be defined (POST via the REST API) and then displayed (GET via the REST API) as long as the has not been restarted in between those 2 requests.. Implement a Spark Streaming Driver application that can be controlled as an XD module instance. Implement a Spark Streaming Receiver that binds to the MessageBus. Define interfaces for Spark Streaming modules. Currently I believe we only mention labels in this section of the doc: And it is not even clear there that they are when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition. We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module, we should add one to illustrate this point.. Composed Module currently behave as \"white boxes\". As soon as a module is composed (say \"http filter\") then all options of the children modules are available (as and in the example above). Change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name). Hardcoding of values would be retained (and possibly overridable). Possible syntaxes : 1) 2) in case of ambiguity (simulated in this particular example): for specifying a default: 3) allow both 1) and 2), using 1) mainly for cases where we don't map 1 to 1 with the underlying option,. tstream create foo \"label: bar xxxx\" stream deploy foo seems to work but it does not. The pre-validation is correct, but downstream, deployment logic still looks for (instead of. Restore deployment properties for orphaned modules. Rename reactor-tcp module to reactor-ip since it also supports udp. Document append configuration, else jdbchdfs writes empty file to hdfs. Document append support, else filepollhdfs writes empty file to hdfs. Create documentation for module property configuration. Add initial support for. The REST API for deploy should accept parameters, which provide manifest key value pairs Ultimately we will want to support passing a named manifest which had been stored previously. The 'stream deploy' shell command should support passing these as Initially we should support .instances and .group.. Also likely rename, remove, or replace that Module (maybe can be supplanted by when used in the refactored parser). Also, considering the \"url\" property is not necessary (vestige of the prototype), all we'd be left with here is the Module name and type, which are used to identify a Module uniquely. Therefore this Module could be renamed to ModuleKey or something. It could be used within the itself. The two classes in question are: The former is currently used by the Admin when making decisions about Module deployment. That latter was a replacement for as we migrated the various Redis InMemory Repositories to use the data that is now available in ZooKeeper instead. The is currently used by the Admin leader, and the is used by the REST endpoint that supports the xd-shell's 'runtime containers' command. Perhaps those can also be merged. In any case, if not addressed by a larger refactoring, the should probably support an Iterable return rather than an Iterator. Having finders for attribute key values such as might be convenient for various Module deployment strategies.. We should also consider explicit methods such as parseStream (so that parseJob and are at least separate methods, if not separate parser classes that share the common parser support class that is the core of today's parser). The parsing for \"completion providers\" should probably be spun off to its own class as well. In the end, there should be no need for a ParsingContext enum but rather, more explicitly named methods and dedicated classes if that seems like the right approach. the should be composed of (that name is not set in stone) and other Stream-level metadata like source sink channels consider merging some of StreamFactory code there, and the rest into StreamDeployer merge and as part of this effort (again, a new name could be considered, but should take precedence over and note in the process that was originally designed to be immutable (taking constructor args), but as we migrated the prototype code into XD itself, this was violated. We may want to consider a builder approach, and we likely want to avoid the need for a within the. all state about the running system (containers, streams, and jobs) should be available via ZK, and ultimately the option should not be needed 1. Refactor to use ZooKeeper remove 2. Refactor to use ZooKeeper remove 3. Refactor to use ZooKeeper (rename remove remove remove the and the remove the associated property key and the *Options properties 6. Remove the events and listeners that were being used. Validate time field processing with. The Admin leader will write each Module deployment request to a child node of for a selected Container (see XD-1399). That (persistent) child node needs to be created by the Container at the same time as it creates its ephemeral node under The Container should then deploy the Module. If that same node is subsequently deleted, the Container should undeploy the Module.. The Stream deployment requests will be written to and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed. When a Stream is deployed, the leader will consult its Container cache and write the modules to the various child nodes (see XD-1400).. This should also enable removal of any code. The state should be written as a data node at the stream level ) For now we at least need to support the boolean flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers (XD-1399). Admin leader should watch Container nodes in ZooKeeper. The xd containers node is the parent where each Container will write an ephemeral child node. The node name should be the Container's ID, and the node data should be the Container's attributes (host, pid, and much more to be added later). When a Container shuts down cleanly, it should eagerly delete the ephemeral node so that watchers are notified immediately. For any other case (including a network partition), the ephemeral node will disappear after the timeout elapses.. Rename or reconsider the command. With PR 340, listing of runtime modules with a non-existent containerId will display empty table. Instead, we can throw exception saying Container doesn't exist.. the top-level URL works via simple curl (without an Accept header) or the browser: However, trying any of those links then fails,. updated story points to 14 since 5 of us just participated in a 2 hour call, and we still need to discuss \"topology\" support after some dev spikes later this week. Retrieve information for a Field Value Counter. Add MBean Exporters to Module. Initial client library for XD REST API. To allow for groups of beans to be defined or not in the container that runs a module. When deploying a stream via the REST API), it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.. Parameterizable streams. add file source and sink modules. ", "contenttype": "application/json", "created": 737358, "id": 9, "language": "en", "user_name": "mark.fisher", "email": "mfisher@gopivotal.com"}]}